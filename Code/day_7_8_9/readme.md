# K Nearest Neighbours (K-NN)

## What is K-NN?

K-NN算法是一种简单的常用的分类算法，同时也可以实现回归计算。

K-NN是一种无参数学习(意味着它不会对底层数据的分布做任何假设)，此算法是基于实例（意味着此算法并没有显式的学习模型，而是选择记忆训练模型），并在一个监督学习中使用。
由于其是基于实例的算法，因此K-NN也被称为惰性算法。

## Making Predictions

若要对未标记的对象进行分类，则会计算出该对象对标记的对象之间的距离，确定其k近邻点，然后使用周边数量最多的最近邻点的类标签来确定该对象的类标签。对于实际中输入的变量，最常用的距离度量是欧氏距离，即$P_1$($x_1$,$y_1$)与$P_2$($x_2$,$y_2$)之间的欧式距离为d=$sqrt{$($x_2$-$x_1$)^2$+$($y_2$-$y_1$)$}$

##  K的取值

K值即我们所要判断类别的点周围点的个数，即近邻的个数。K值取值大小并不容易判断，若K值太小，则结果受噪声影响较大;若K值太大,则我们的计算成本会大大增加。在实际应用过程中，最好是遍历每个可能的K值，然后根据自身项目要求选取最合适的K值。

## How Does K-NN Algorithm work？

K-NN算法用于分类时，将K个近邻中出现频率最高的作为我们的分类类别。

## Other  Distance Calculation Method

欧氏距离计算一个新点和一个现有点在所有输入属性上的差的平方之和的平方根。
其他常见的距离度量方法包括：
- Hamming Distance(汉明距离)
- Manhattan Distance(曼哈顿距离)
- Minkowski Distance(闵氏距离)
